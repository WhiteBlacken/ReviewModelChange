{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from docx import Document\n",
    "from textstat import textstat\n",
    "from torch import nn\n",
    "from transformers import XLNetTokenizerFast, XLNetModel, BertTokenizer, BertForMaskedLM\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchmetrics.classification import MultilabelPrecision, MultilabelRecall, MultilabelAccuracy, MultilabelF1Score, MultilabelHammingDistance, Accuracy, Precision, Recall, F1Score, BinaryAccuracy, BinaryPrecision, BinaryRecall, BinaryF1Score\n",
    "import sklearn\n",
    "from keybert import KeyBERT\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "xlnet_tokenizer = XLNetTokenizerFast.from_pretrained(\"xlnet-base-cased\")\n",
    "xlnet_model = XLNetModel.from_pretrained(\"xlnet-base-cased\", output_attentions=True)\n",
    "xlnet_model.eval()\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()\n",
    "kw_model = KeyBERT()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<function Tensor.view>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = torch.rand((1,2,3))\n",
    "# a.view\n",
    "\n",
    "# from torch.nn.modules.container import ModuleList\n",
    "# import copy\n",
    "#\n",
    "# class WordSentenceSplitTransformerEncoder(nn.TransformerEncoder):\n",
    "#\n",
    "#     def __init__(self, encoder_layers, num_layers, norm=None, enable_nested_tensor=False):\n",
    "#         super(nn.TransformerEncoder, self).__init__()\n",
    "#         self.layers = ModuleList(encoder_layers)\n",
    "#         self.num_layers = num_layers\n",
    "#         self.norm = norm\n",
    "#         self.enable_nested_tensor = enable_nested_tensor\n",
    "\n",
    "# def hook(module, fea_in, fea_out):\n",
    "#     print(fea_in[0].shape)\n",
    "#     print(module.get_parameter())\n",
    "#     print('hooking!')\n",
    "#\n",
    "# model = ClassificationModel(24)\n",
    "# tgt_name = 'transformer_encoder.layers.1.self_attn'\n",
    "# for name, module in model.named_modules():\n",
    "#     if name == tgt_name:\n",
    "#         module.register_forward_hook(hook=hook)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([32, 538, 1]),\n torch.Size([32, 6, 1]),\n torch.Size([32, 538, 1]),\n torch.Size([32, 6, 2]))"
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ClassificationModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, transformer_in_feature_size=768, transformer_out_feature_size=64, difficulty_feature_size=3, topic_feature_size=1, eye_feature_size=12, head_num=10, layer_count=2):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        feature_size = transformer_out_feature_size + difficulty_feature_size + topic_feature_size + eye_feature_size\n",
    "        self.transformer_linear = nn.Linear(in_features=transformer_in_feature_size, out_features=transformer_out_feature_size)\n",
    "        self.normalize = nn.LayerNorm\n",
    "        self.transformer_encoder_ahead_layers = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=feature_size, nhead=head_num, batch_first=True),\n",
    "            num_layers=layer_count - 1,\n",
    "        )\n",
    "        self.transformer_encoder_word_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=head_num, batch_first=True)\n",
    "        self.transformer_encoder_sent_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=head_num, batch_first=True)\n",
    "\n",
    "        # self.mask = torch.tensor([])\n",
    "\n",
    "        self.word_normal_linear = nn.Linear(in_features=feature_size, out_features=1)\n",
    "        self.sent_normal_linear = nn.Linear(in_features=feature_size, out_features=1)\n",
    "        self.word_normal_activation = nn.Sigmoid()\n",
    "        self.sent_normal_activation = nn.Sigmoid()\n",
    "\n",
    "        self.word_multilabel_linear = nn.Linear(in_features=feature_size, out_features=1)\n",
    "        self.sent_multilabel_linear = nn.Linear(in_features=feature_size, out_features=2)\n",
    "        self.word_multilabel_activation = nn.Sigmoid()\n",
    "        self.sent_multilabel_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, transformer_features, difficulty_features, topic_features, eye_features, sent_ranges):\n",
    "        current_device = next(self.parameters()).device\n",
    "        compressed_transformer_features = self.transformer_linear(transformer_features)\n",
    "        word_features = torch.concat((compressed_transformer_features, eye_features, difficulty_features, topic_features), dim=-1)\n",
    "        word_features = self.transformer_encoder_ahead_layers(word_features)\n",
    "\n",
    "        word_count = transformer_features.shape[-2]\n",
    "\n",
    "        word_mask = torch.concat([torch.zeros((8, word_count, word_count)), torch.ones((2, word_count, word_count))]).to(current_device)\n",
    "        sent_mask = torch.concat([torch.ones((2, word_count, word_count)), torch.zeros((8, word_count, word_count))]).to(current_device)\n",
    "        if len(transformer_features.shape) > 2:\n",
    "            batch_size = transformer_features.shape[0]\n",
    "            word_mask = word_mask.repeat((batch_size, 1, 1))\n",
    "            sent_mask = sent_mask.repeat((batch_size, 1, 1))\n",
    "            word_level_encoded_features = self.transformer_encoder_word_layer(word_features, src_mask=word_mask)\n",
    "            sent_level_encoded_features = self.transformer_encoder_sent_layer(word_features, src_mask=sent_mask)\n",
    "            sent_level_encoded_features = torch.concat(\n",
    "                [torch.mean(sent_level_encoded_features[ : , start_id : end_id + 1, : ], dim=-2, keepdim=True) for [start_id, end_id] in sent_ranges],\n",
    "                dim=-2,\n",
    "            )\n",
    "            # print(sent_level_encoded_features.shape)\n",
    "        else:\n",
    "            word_level_encoded_features = self.transformer_encoder_word_layer(word_features, src_mask=word_mask)\n",
    "            sent_level_encoded_features = self.transformer_encoder_sent_layer(word_features, src_mask=sent_mask)\n",
    "            sent_level_encoded_features = torch.concat(\n",
    "                [torch.mean(sent_level_encoded_features[start_id : end_id + 1, : ], dim=-2, keepdim=True) for [start_id, end_id] in sent_ranges],\n",
    "                dim=-2,\n",
    "            )\n",
    "\n",
    "        word_normal_features = self.word_normal_linear(word_level_encoded_features)\n",
    "        sent_normal_features = self.sent_normal_linear(sent_level_encoded_features)\n",
    "        word_normal_classifications = self.word_normal_activation(word_normal_features)\n",
    "        sent_normal_classifications = self.sent_normal_activation(sent_normal_features)\n",
    "\n",
    "        word_multilabel_features = self.word_multilabel_linear(word_level_encoded_features)\n",
    "        sent_multilabel_features = self.sent_multilabel_linear(sent_level_encoded_features)\n",
    "        word_multilabel_classifications = self.word_multilabel_activation(word_multilabel_features)\n",
    "        sent_multilabel_classifications = self.sent_multilabel_activation(sent_multilabel_features)\n",
    "\n",
    "        return word_normal_classifications, sent_normal_classifications, word_multilabel_classifications, sent_multilabel_classifications\n",
    "\n",
    "# just for test\n",
    "BATCH_NUM = 32\n",
    "WORD_COUNT = 538\n",
    "TRANSFORMER_IN_FEAT_SIZE = 768\n",
    "TRANSFORMER_OUT_FEAT_SIZE = 64\n",
    "EYE_FEAT_SIZE = 12\n",
    "DIFFICULTY_FEAT_SIZE = 3\n",
    "TOPIC_FEAT_SIZE = 1\n",
    "\n",
    "test_model = ClassificationModel(TRANSFORMER_IN_FEAT_SIZE, TRANSFORMER_OUT_FEAT_SIZE, DIFFICULTY_FEAT_SIZE, TOPIC_FEAT_SIZE, EYE_FEAT_SIZE)\n",
    "transformer_feats = torch.rand(BATCH_NUM, WORD_COUNT, TRANSFORMER_IN_FEAT_SIZE)\n",
    "eye_feats = torch.rand(BATCH_NUM, WORD_COUNT, EYE_FEAT_SIZE)\n",
    "difficulty_feats = torch.rand(BATCH_NUM, WORD_COUNT, DIFFICULTY_FEAT_SIZE)\n",
    "topic_feats = torch.rand(BATCH_NUM, WORD_COUNT, TOPIC_FEAT_SIZE)\n",
    "sent_rs = [(0, 99), (100, 199), (200, 299), (300, 399), (400, 499), (500, 537)]\n",
    "word_normal_cls, sent_normal_cls, word_multilabel_cls, sent_multilabel_cls = test_model(transformer_feats, difficulty_feats, topic_feats, eye_feats, sent_rs)\n",
    "word_normal_cls.shape, sent_normal_cls.shape, word_multilabel_cls.shape, sent_multilabel_cls.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_docx_text(docx_path):\n",
    "    document = Document(docx_path)\n",
    "    read_text = ''\n",
    "    for pa in document.paragraphs:\n",
    "        read_text += pa.text + ' '\n",
    "    return read_text\n",
    "\n",
    "\n",
    "class ReadingArticle:\n",
    "\n",
    "    all_difficulty_values = [[], [], []]\n",
    "\n",
    "    word_fam_map = {}\n",
    "    with open('/home/wtpan/memx4edu-code/mrc2.dct', 'r') as fp:\n",
    "        i = 0\n",
    "        for line in fp:\n",
    "            line = line.strip()\n",
    "\n",
    "            word, phon, dphon, stress = line[51:].split('|')\n",
    "\n",
    "            w = {\n",
    "                'wid': i,\n",
    "                'nlet': int(line[0:2]),\n",
    "                'nphon': int(line[2:4]),\n",
    "                'nsyl': int(line[4]),\n",
    "                'kf_freq': int(line[5:10]),\n",
    "                'kf_ncats': int(line[10:12]),\n",
    "                'kf_nsamp': int(line[12:15]),\n",
    "                'tl_freq': int(line[15:21]),\n",
    "                'brown_freq': int(line[21:25]),\n",
    "                'fam': int(line[25:28]),\n",
    "                'conc': int(line[28:31]),\n",
    "                'imag': int(line[31:34]),\n",
    "                'meanc': int(line[34:37]),\n",
    "                'meanp': int(line[37:40]),\n",
    "                'aoa': int(line[40:43]),\n",
    "                'tq2': line[43],\n",
    "                'wtype': line[44],\n",
    "                'pdwtype': line[45],\n",
    "                'alphasyl': line[46],\n",
    "                'status': line[47],\n",
    "                'var': line[48],\n",
    "                'cap': line[49],\n",
    "                'irreg': line[50],\n",
    "                'word': word,\n",
    "                'phon': phon,\n",
    "                'dphon': dphon,\n",
    "                'stress': stress\n",
    "            }\n",
    "            if word not in word_fam_map:\n",
    "                word_fam_map[word] = w['fam']\n",
    "            word_fam_map[word] = max(word_fam_map[word], w['fam'])\n",
    "            i += 1\n",
    "\n",
    "    def __init__(self, article_id, article_text):\n",
    "        self.id = article_id\n",
    "        self.text = article_text\n",
    "        self._spacy_doc = nlp(article_text)\n",
    "        self._word_list = [token.text for token in self._spacy_doc]\n",
    "        self._transformer_features = self._generate_word_embedding()\n",
    "        self._difficulty_features = self._generate_word_difficulty()\n",
    "        self._topic_features = self._generate_topic_rate(top_n=5)\n",
    "        self._sentence_word_mapping = self._generate_sentence_mapping()\n",
    "\n",
    "    def _generate_word_embedding(self):\n",
    "        inputs = xlnet_tokenizer(self.text, return_tensors='pt')\n",
    "        word_token_mapping = self.generate_token_mapping(self._word_list, inputs.tokens())\n",
    "        outputs = xlnet_model(**inputs)\n",
    "        token_embeddings = outputs[0].squeeze()\n",
    "        word_embeddings = []\n",
    "        for start_id, end_id in word_token_mapping:\n",
    "            if start_id <= end_id:\n",
    "                word_embeddings.append(torch.mean(token_embeddings[start_id : end_id + 1, :], 0, dtype=torch.float32))\n",
    "            else:\n",
    "                word_embeddings.append(torch.zeros((token_embeddings.shape[1],), dtype=torch.float32))\n",
    "        return word_embeddings\n",
    "\n",
    "    def _generate_sentence_mapping(self):\n",
    "        sentences = sent_tokenize(self.text)\n",
    "        sentence_word_mapping = self.generate_token_mapping(sentences, self._word_list)\n",
    "        return sentence_word_mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_token_mapping(string_list, token_list):\n",
    "        string_pos = 0\n",
    "        string_idx = 0\n",
    "        token_string_idx_list = []\n",
    "        max_cross_count = 3\n",
    "        for token_idx, token in enumerate(token_list):\n",
    "            original_token = token.replace('▁', '')\n",
    "            flag = False\n",
    "            while string_idx < len(string_list) and string_list[string_idx][string_pos : string_pos + len(original_token)] != original_token:\n",
    "                string_pos += 1\n",
    "                if string_pos >= len(string_list[string_idx]):\n",
    "                    cross_count = 1\n",
    "                    prefix = string_list[string_idx]\n",
    "                    pre_length = len(string_list[string_idx])\n",
    "                    while cross_count <= max_cross_count and string_idx + cross_count < len(string_list):\n",
    "                        prefix += string_list[string_idx + cross_count]\n",
    "                        new_string_pos = 0\n",
    "                        while new_string_pos + len(original_token) <= len(prefix) and new_string_pos < len(string_list[string_idx]):\n",
    "                            if prefix[new_string_pos : new_string_pos + len(original_token)] == original_token and new_string_pos + len(original_token) > len(string_list[string_idx]):\n",
    "                                string_pos = new_string_pos + len(original_token) - pre_length\n",
    "                                flag = True\n",
    "                                break\n",
    "                            new_string_pos += 1\n",
    "                        if flag:\n",
    "                            break\n",
    "                        pre_length += len(string_list[string_idx + cross_count])\n",
    "                        cross_count += 1\n",
    "                    if flag:\n",
    "                        for delta_idx in range(cross_count + 1):\n",
    "                            token_string_idx_list.append((token_idx, string_idx + delta_idx))\n",
    "                        string_idx += cross_count\n",
    "                        if string_idx < len(string_list) and string_pos == len(string_list[string_idx]):\n",
    "                            string_pos = 0\n",
    "                            string_idx += 1\n",
    "                        break\n",
    "                    else:\n",
    "                        string_pos = 0\n",
    "                        string_idx += 1\n",
    "            if flag:\n",
    "                continue\n",
    "            if string_idx < len(string_list) and string_pos == len(string_list[string_idx]):\n",
    "                string_pos = 0\n",
    "                string_idx += 1\n",
    "            if string_idx >= len(string_list):\n",
    "                continue\n",
    "            token_string_idx_list.append((token_idx, string_idx))\n",
    "            string_pos += len(original_token)\n",
    "\n",
    "        # for token_idx, string_idx in token_string_idx_list:\n",
    "        #     print(inputs.tokens()[token_idx], string_list[string_idx])\n",
    "\n",
    "        string_token_mapping = [(float('inf'), 0)] * len(string_list)\n",
    "        for token_idx, string_idx in token_string_idx_list:\n",
    "            string_token_mapping[string_idx] = (min(string_token_mapping[string_idx][0], token_idx), max(string_token_mapping[string_idx][1], token_idx))\n",
    "\n",
    "        return string_token_mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def get_word_familiar_rate(word_text):\n",
    "        capital_word = word_text.upper()\n",
    "        return ReadingArticle.word_fam_map.get(capital_word, 0)\n",
    "\n",
    "    def _generate_word_difficulty(self):\n",
    "        word_difficulties = []\n",
    "        for token in self._spacy_doc:\n",
    "            if token.is_alpha and not token.is_stop:\n",
    "                fam = self.get_word_familiar_rate(token.text)\n",
    "                if fam == 0:\n",
    "                    fam = self.get_word_familiar_rate(token.lemma_)\n",
    "                syllable = textstat.syllable_count(token.text)\n",
    "                length = len(token.text)\n",
    "                score_tensor = torch.tensor([\n",
    "                    # float(textstat.syllable_count(token.text) > 2),\n",
    "                    # float(len(token.text) > 7),\n",
    "                    # float(fam < 482),\n",
    "                    float(syllable),\n",
    "                    float(length),\n",
    "                    float(fam)\n",
    "                ])\n",
    "                ReadingArticle.all_difficulty_values[0].append(syllable)\n",
    "                ReadingArticle.all_difficulty_values[1].append(length)\n",
    "                ReadingArticle.all_difficulty_values[2].append(fam)\n",
    "            else:\n",
    "                score_tensor = torch.zeros((3,))\n",
    "            word_difficulties.append(score_tensor)\n",
    "        return word_difficulties\n",
    "\n",
    "    def _generate_topic_rate(self, top_n):\n",
    "        keywords = kw_model.extract_keywords(self.text, keyphrase_ngram_range=(1,1), stop_words=None, top_n=top_n)\n",
    "        keywords = {k: v for k, v in keywords}\n",
    "        # print(keywords)\n",
    "        topic_rate = []\n",
    "        for token in self._spacy_doc:\n",
    "            topic_rate.append(torch.tensor([keywords.get(token.text, 0.)]))\n",
    "        return topic_rate\n",
    "\n",
    "    def get_word_filter_id_set(self, only_alpha=True, filter_digit=True, filter_punctuation=True, filter_stop_words=False):\n",
    "        word_filter_id_set = set()\n",
    "        for word in self._spacy_doc:\n",
    "            if only_alpha and not word.is_alpha:\n",
    "                word_filter_id_set.add(word.i)\n",
    "            if filter_digit and word.is_digit:\n",
    "                word_filter_id_set.add(word.i)\n",
    "            if filter_punctuation and word.is_punct:\n",
    "                word_filter_id_set.add(word.i)\n",
    "            if filter_stop_words and word.is_stop:\n",
    "                word_filter_id_set.add(word.i)\n",
    "        return word_filter_id_set\n",
    "\n",
    "    def get_word_list(self):\n",
    "        return self._word_list\n",
    "\n",
    "    def get_transformer_features(self):\n",
    "        return self._transformer_features\n",
    "\n",
    "    def get_difficulty_features(self):\n",
    "        values = []\n",
    "        mean_values = [np.mean(values) for values in ReadingArticle.all_difficulty_values]\n",
    "        std_values = [np.std(values) for values in ReadingArticle.all_difficulty_values]\n",
    "        for feature in self._difficulty_features:\n",
    "            values.append(torch.tensor([(feature[column] - mean_values[column]) / std_values[column] for column in range(3)], dtype=torch.float32))\n",
    "        return values\n",
    "        # return self._difficulty_features\n",
    "\n",
    "    def get_topic_features(self):\n",
    "        return self._topic_features\n",
    "\n",
    "    def get_sentence_word_mapping(self):\n",
    "        return self._sentence_word_mapping\n",
    "\n",
    "\n",
    "class ReadingExperiment:\n",
    "\n",
    "    all_values = {\n",
    "        'word_understand': [],\n",
    "        'reading_times': [],\n",
    "        'number_of_fixations': [],\n",
    "        'second_pass_dwell_time_of_sentence': [],\n",
    "        'total_dwell_time_of_sentence': [],\n",
    "        'reading_times_of_sentence': [],\n",
    "        'saccade_times_of_sentence': [],\n",
    "        'forward_times_of_sentence': [],\n",
    "        'backward_times_of_sentence': [],\n",
    "        # 'saccade_times_of_para': [],\n",
    "        # 'forward_saccade_times_of_para': [],\n",
    "        # 'backward_saccade_times_of_para': [],\n",
    "    }\n",
    "\n",
    "    mean_values = {}\n",
    "    std_values = {}\n",
    "\n",
    "    def __init__(self, experiment_id, user, article_id, timestamp):\n",
    "        self.id = experiment_id\n",
    "        self.user = user\n",
    "        self.article_id = article_id\n",
    "        self.timestamp = timestamp\n",
    "        self.reading_records = []\n",
    "        self.default_record = {\n",
    "            'word': '',\n",
    "            'word_understand': 0.,\n",
    "            'word_watching': 0.,\n",
    "            'sentence_understand': 0.,\n",
    "            'mind_wandering': 0.,\n",
    "            'reading_times': 0.,\n",
    "            'number_of_fixations': 0.,\n",
    "            'second_pass_dwell_time_of_sentence': 0.,\n",
    "            'total_dwell_time_of_sentence': 0.,\n",
    "            'reading_times_of_sentence': 0.,\n",
    "            'saccade_times_of_sentence': 0.,\n",
    "            'forward_times_of_sentence': 0.,\n",
    "            'backward_times_of_sentence': 0.,\n",
    "            # 'saccade_times_of_para': 0.,\n",
    "            # 'forward_saccade_times_of_para': 0.,\n",
    "            # 'backward_saccade_times_of_para': 0.,\n",
    "        }\n",
    "        self.article_record_word_id_map = {}\n",
    "        self.record_article_word_id_map = {}\n",
    "\n",
    "    def add_reading_record(self, **kwargs):\n",
    "        reading_record = self.default_record.copy()\n",
    "        reading_record.update(**kwargs)\n",
    "        for key in ReadingExperiment.all_values:\n",
    "            ReadingExperiment.all_values[key].append(reading_record[key])\n",
    "        self.reading_records.append(reading_record)\n",
    "\n",
    "    def get_word_list(self):\n",
    "        return [record['word'] for record in self.reading_records]\n",
    "\n",
    "    def get_normalized_features(self, columns):\n",
    "        values = []\n",
    "        if not ReadingExperiment.mean_values or not ReadingExperiment.std_values:\n",
    "            # print('haha first time')\n",
    "            ReadingExperiment.mean_values = {key: np.mean(values) for key, values in ReadingExperiment.all_values.items()}\n",
    "            ReadingExperiment.std_values = {key: np.std(values) for key, values in ReadingExperiment.all_values.items()}\n",
    "        for record in self.reading_records:\n",
    "            values.append(torch.tensor([(record[column] - ReadingExperiment.mean_values[column]) / ReadingExperiment.std_values[column] if ReadingExperiment.std_values[column] != 0. else 0. for column in columns], dtype=torch.float32))\n",
    "        return values\n",
    "\n",
    "    def get_values(self, columns, reverse=False):\n",
    "        values = []\n",
    "        if reverse:\n",
    "            for record in self.reading_records:\n",
    "                values.append([1 - record[column] for column in columns])\n",
    "        else:\n",
    "            for record in self.reading_records:\n",
    "                values.append([record[column] for column in columns])\n",
    "        return values\n",
    "\n",
    "\n",
    "class ReadingDataset(Dataset):\n",
    "\n",
    "    def __init__(self, reading_articles_path, reading_experiments_path, eye_feature_names, eye_feature_size, word_label_names, sent_label_names, word_watching_label_name, article_word_mismatch_thr, record_word_mismatch_thr):\n",
    "        self.eye_feature_names = eye_feature_names\n",
    "        self.eye_feature_size = eye_feature_size\n",
    "        if eye_feature_size < len(eye_feature_names):\n",
    "            raise Exception\n",
    "        self.word_label_names = word_label_names\n",
    "        self.sent_label_names = sent_label_names\n",
    "        self.word_watching_label_name = word_watching_label_name\n",
    "        self.article_word_mismatch_thr = article_word_mismatch_thr\n",
    "        self.record_word_mismatch_thr = record_word_mismatch_thr\n",
    "\n",
    "        self.article_record_word_ids_mapping = {}\n",
    "\n",
    "        self.article_id_map = {}\n",
    "        with open(reading_articles_path) as fp:\n",
    "            cr = csv.reader(fp)\n",
    "            for row in cr:\n",
    "                article_id = int(row[0])\n",
    "                article_text = row[1]\n",
    "                article = ReadingArticle(article_id, article_text)\n",
    "                self.article_id_map[article_id] = article\n",
    "\n",
    "        self.experiment_id_timestamp_map = {}\n",
    "        df = pd.read_csv(reading_experiments_path)\n",
    "        all_records = df.to_dict('records')\n",
    "        for record in all_records:\n",
    "            experiment_id = record['experiment_id']\n",
    "            user = record['user']\n",
    "            article_id = record['article_id']\n",
    "            timestamp = record['time']\n",
    "            # word_watching = record['word_watching']\n",
    "            # timestamp = -1\n",
    "            if experiment_id not in self.experiment_id_timestamp_map:\n",
    "                self.experiment_id_timestamp_map[experiment_id] = {}\n",
    "            if timestamp not in self.experiment_id_timestamp_map[experiment_id]:\n",
    "                self.experiment_id_timestamp_map[experiment_id][timestamp] = ReadingExperiment(experiment_id, user, article_id, timestamp)\n",
    "            self.experiment_id_timestamp_map[experiment_id][timestamp].add_reading_record(**record)\n",
    "        # print(self.experiment_id_timestamp_map)\n",
    "        self.experiments = [v for vs in self.experiment_id_timestamp_map.values() for v in vs.values()]\n",
    "        # print(self.experiments)\n",
    "\n",
    "        ti = time.time()\n",
    "        self.experiment_data = []\n",
    "        self.experiment_lengths = []\n",
    "        for experiment in tqdm(self.experiments):\n",
    "            eye_features = experiment.get_normalized_features(self.eye_feature_names)\n",
    "            word_multilabel_single_labels = experiment.get_values(self.word_label_names, reverse=True)\n",
    "            sent_multilabel_single_labels = experiment.get_values(self.sent_label_names, reverse=True)\n",
    "            word_watching_situations = experiment.get_values([self.word_watching_label_name])\n",
    "            article = self.article_id_map[experiment.article_id]\n",
    "            transformer_features = article.get_transformer_features()\n",
    "            difficulty_features = article.get_difficulty_features()\n",
    "            topic_features = article.get_topic_features()\n",
    "            word_filter_id_set = article.get_word_filter_id_set()\n",
    "            sentence_word_mapping = article.get_sentence_word_mapping()\n",
    "            article_word_list = article.get_word_list()\n",
    "            article_record_word_ids = self._match_article_record_word_list(article, experiment)\n",
    "\n",
    "            filtered_transformer_features = []\n",
    "            filtered_difficulty_features = []\n",
    "            filtered_topic_features = []\n",
    "            filtered_eye_features = []\n",
    "\n",
    "            filtered_word_watching_situations = []\n",
    "            filtered_sent_watching_situations = [False]\n",
    "\n",
    "            filtered_word_normal_labels = []\n",
    "            filtered_sent_normal_labels = [True]\n",
    "\n",
    "            filtered_word_multilabel_labels = []\n",
    "            filtered_sent_multilabel_labels = [[False, False]]\n",
    "\n",
    "            filtered_sent_word_mapping = [(0, 0)]\n",
    "\n",
    "            filtered_word_list = []\n",
    "\n",
    "            current_sentence_id = 0\n",
    "            current_word_id = 0\n",
    "            for article_word_id, record_word_id in article_record_word_ids:\n",
    "                if article_word_id not in word_filter_id_set:\n",
    "                    filtered_transformer_features.append(transformer_features[article_word_id])\n",
    "                    filtered_difficulty_features.append(difficulty_features[article_word_id])\n",
    "                    filtered_topic_features.append(topic_features[article_word_id])\n",
    "                    filtered_eye_features.append(torch.concat([eye_features[record_word_id], torch.zeros(self.eye_feature_size - len(self.eye_feature_names))]))\n",
    "\n",
    "                    filtered_word_watching_situations.append(word_watching_situations[record_word_id][0])\n",
    "\n",
    "                    filtered_word_normal_labels.append(sum(word_multilabel_single_labels[record_word_id]) == 0)\n",
    "\n",
    "                    filtered_word_multilabel_labels.append(word_multilabel_single_labels[record_word_id])\n",
    "\n",
    "                    filtered_word_list.append(article_word_list[article_word_id])\n",
    "\n",
    "                    if article_word_id > sentence_word_mapping[current_sentence_id][1]:\n",
    "                        while article_word_id > sentence_word_mapping[current_sentence_id][1]:\n",
    "                            current_sentence_id += 1\n",
    "                        filtered_sent_word_mapping.append((current_word_id, current_word_id))\n",
    "                        filtered_sent_watching_situations.append(word_watching_situations[record_word_id][0])\n",
    "                        filtered_sent_normal_labels.append(sum(sent_multilabel_single_labels[record_word_id]) == 0)\n",
    "                        filtered_sent_multilabel_labels.append(torch.tensor(sent_multilabel_single_labels[record_word_id]))\n",
    "                    else:\n",
    "                        filtered_sent_word_mapping[-1] = (filtered_sent_word_mapping[-1][0], current_word_id)\n",
    "                        filtered_sent_watching_situations[-1] |= word_watching_situations[record_word_id][0]\n",
    "                        filtered_sent_normal_labels[-1] &= sum(sent_multilabel_single_labels[record_word_id]) == 0\n",
    "                        filtered_sent_multilabel_labels[-1] = tuple(x | y for x, y in zip(filtered_sent_multilabel_labels[-1], sent_multilabel_single_labels[record_word_id]))\n",
    "                    current_word_id += 1\n",
    "\n",
    "            # filtered_word_watching_situations = [torch.tensor(word_watching_situation, dtype=torch.float) for word_watching_situation in filtered_word_watching_situations]\n",
    "            # filtered_sent_watching_situations = [torch.tensor(sent_watching_situation, dtype=torch.float) for sent_watching_situation in filtered_sent_watching_situations]\n",
    "            filtered_word_normal_labels = [torch.tensor([1.] if word_normal_label else [0.]) for word_normal_label in filtered_word_normal_labels]\n",
    "            filtered_sent_normal_labels = [torch.tensor([1.] if sent_normal_label else [0.]) for sent_normal_label in filtered_sent_normal_labels]\n",
    "            filtered_word_multilabel_labels = [torch.tensor(word_multilabel_label, dtype=torch.float) for word_multilabel_label in filtered_word_multilabel_labels]\n",
    "            filtered_sent_multilabel_labels = [torch.tensor(sent_multilabel_label, dtype=torch.float) for sent_multilabel_label in filtered_sent_multilabel_labels]\n",
    "            # print(article_record_word_ids)\n",
    "            # print(filtered_transformer_features)\n",
    "            self.experiment_data.append((\n",
    "                torch.stack(filtered_transformer_features).detach(),\n",
    "                torch.stack(filtered_difficulty_features),\n",
    "                torch.stack(filtered_topic_features),\n",
    "                torch.stack(filtered_eye_features),\n",
    "\n",
    "                torch.stack(filtered_word_normal_labels),\n",
    "                torch.stack(filtered_sent_normal_labels),\n",
    "                torch.stack(filtered_word_multilabel_labels),\n",
    "                torch.stack(filtered_sent_multilabel_labels),\n",
    "\n",
    "                torch.tensor(filtered_sent_word_mapping),\n",
    "\n",
    "                # torch.tensor(filtered_word_list),\n",
    "\n",
    "                torch.tensor(filtered_word_watching_situations),\n",
    "                torch.tensor(filtered_sent_watching_situations),\n",
    "            ))\n",
    "\n",
    "        print(time.time() - ti)\n",
    "            # self.experiment_lengths.append(len(filtered_transformer_features))\n",
    "\n",
    "    def __len__(self):\n",
    "        # return sum(self.experiment_lengths)\n",
    "        return len(self.experiments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # current_exp_idx = 0\n",
    "        # while idx - self.experiment_lengths[current_exp_idx] >= 0:\n",
    "        #     idx -= self.experiment_lengths[current_exp_idx]\n",
    "        #     current_exp_idx += 1\n",
    "        # return self.experiment_data[idx], torch.tensor([idx])\n",
    "        return self.experiment_data[idx]\n",
    "\n",
    "    def _match_article_record_word_list(self, article, experiment):\n",
    "        if (article.id, experiment.id) in self.article_record_word_ids_mapping:\n",
    "            return self.article_record_word_ids_mapping[(article.id, experiment.id)]\n",
    "        article_word_list = article.get_word_list()\n",
    "        record_word_list = experiment.get_word_list()\n",
    "\n",
    "        article_record_word_ids = []\n",
    "\n",
    "        article_word_id, record_word_id = 0, 0\n",
    "        while article_word_id < len(article_word_list) and record_word_id < len(record_word_list):\n",
    "            if article_word_list[article_word_id] == record_word_list[record_word_id]:\n",
    "                article_record_word_ids.append((article_word_id, record_word_id))\n",
    "                # print(article_word_id, record_word_id, article_word_list[article_word_id])\n",
    "                article_word_id += 1\n",
    "                record_word_id += 1\n",
    "            else:\n",
    "                delta_id = 1\n",
    "                flag = False\n",
    "                while delta_id < self.article_word_mismatch_thr and article_word_id + delta_id < len(article_word_list):\n",
    "                    cur_article_word_id = article_word_id + delta_id\n",
    "                    if article_word_list[cur_article_word_id] == record_word_list[record_word_id]:\n",
    "                        article_record_word_ids.append((cur_article_word_id, record_word_id))\n",
    "                        # print(cur_article_word_id, record_word_id, article_word_list[cur_article_word_id])\n",
    "                        article_word_id = cur_article_word_id + 1\n",
    "                        record_word_id += 1\n",
    "                        flag = True\n",
    "                        break\n",
    "                    delta_id += 1\n",
    "                if flag:\n",
    "                    continue\n",
    "\n",
    "                delta_id = 1\n",
    "                flag = False\n",
    "                while delta_id < self.record_word_mismatch_thr and record_word_id + delta_id < len(record_word_list):\n",
    "                    cur_record_word_id = record_word_id + delta_id\n",
    "                    if article_word_list[article_word_id] == record_word_list[cur_record_word_id]:\n",
    "                        article_record_word_ids.append((article_word_id, cur_record_word_id))\n",
    "                        # print(article_word_id, cur_record_word_id, article_word_list[article_word_id])\n",
    "                        article_word_id += 1\n",
    "                        record_word_id = cur_record_word_id + 1\n",
    "                        flag = True\n",
    "                        break\n",
    "                    delta_id += 1\n",
    "                if flag:\n",
    "                    continue\n",
    "\n",
    "                article_word_id += 1\n",
    "                record_word_id += 1\n",
    "\n",
    "        self.article_record_word_ids_mapping[(article.id, experiment.id)] = article_record_word_ids\n",
    "        return article_record_word_ids\n",
    "\n",
    "\n",
    "EYE_FEATURE_NAMES = [\n",
    "    'reading_times',\n",
    "    'number_of_fixations',\n",
    "    'second_pass_dwell_time_of_sentence',\n",
    "    'total_dwell_time_of_sentence',\n",
    "    'reading_times_of_sentence',\n",
    "    'saccade_times_of_sentence',\n",
    "    'forward_times_of_sentence',\n",
    "    'backward_times_of_sentence',\n",
    "    # 'saccade_times_of_para',\n",
    "    # 'forward_saccade_times_of_para',\n",
    "    # 'backward_saccade_times_of_para',\n",
    "]\n",
    "WORD_LABEL_NAMES = [\n",
    "    'word_understand',\n",
    "]\n",
    "SENT_LABEL_NAMES = [\n",
    "    'sentence_understand',\n",
    "    'mind_wandering',\n",
    "]\n",
    "WORD_WATCHING_LABEL_NAME = 'word_watching'\n",
    "dataset = ReadingDataset(\n",
    "    reading_articles_path='/home/wtpan/memx4edu-code/training_data/article.csv',\n",
    "    # reading_experiments_path='/home/wtpan/memx4edu-code/training_data/2022-10-28_4test.csv',\n",
    "    reading_experiments_path='/home/wtpan/memx4edu-code/training_data/2022-10-28.csv',\n",
    "    eye_feature_names=EYE_FEATURE_NAMES,\n",
    "    eye_feature_size=12,\n",
    "    word_label_names=WORD_LABEL_NAMES,\n",
    "    sent_label_names=SENT_LABEL_NAMES,\n",
    "    word_watching_label_name=WORD_WATCHING_LABEL_NAME,\n",
    "    article_word_mismatch_thr=10,\n",
    "    record_word_mismatch_thr=3,\n",
    ")\n",
    "len(dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[  0,  70],\n        [ 71, 111],\n        [112, 144],\n        [145, 163],\n        [164, 179],\n        [180, 187],\n        [188, 207],\n        [208, 218],\n        [219, 253],\n        [254, 269],\n        [270, 288],\n        [289, 316],\n        [317, 336],\n        [337, 393],\n        [394, 423]])"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_features, difficulty_features, topic_features, eye_features, word_normal_labels, sent_normal_labels, word_multilabel_labels, sent_multilabel_labels, sent_word_mapping, word_watching_situations, sent_watching_situations = dataset[0]\n",
    "sent_word_mapping"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [
    {
     "data": {
      "text/plain": "43"
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_count = int(0.8 * len(dataset))\n",
    "val_count = len(dataset) - train_count\n",
    "train_dataset, val_dataset = random_split(dataset, (train_count, val_count))\n",
    "# TODO: batch_size\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1)\n",
    "len(train_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([1]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0]), tensor([0])]\n"
     ]
    }
   ],
   "source": [
    "for a in train_dataloader:\n",
    "    transformer_features, difficulty_features, topic_features, eye_features, word_normal_labels, sent_normal_labels, word_multilabel_labels, sent_multilabel_labels, sent_word_mapping, word_list, word_watching_situations, sent_watching_situations = a\n",
    "    print(word_watching_situations)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor(0.)"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[[1,0], [1,0], [1,0], [1,0], [1,0]]], dtype=torch.float)\n",
    "b = torch.tensor([[[1,0], [1,0], [1,0], [1,0], [1,0]]], dtype=torch.float)\n",
    "w = torch.tensor([[[1,1], [1,1], [1,1], [1,1], [1,1]]], dtype=torch.float)\n",
    "print(a.shape)\n",
    "nn.BCELoss(weight=w)(a,b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "0 0.000761026733143385\n",
      "1 0.0007286608912223994\n",
      "2 0.0006973510391490404\n",
      "3 0.0006709064595228017\n",
      "4 0.0006443746821131817\n",
      "5 0.0006221193213795507\n",
      "6 0.0006008523321428964\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [186], line 36\u001B[0m\n\u001B[1;32m     34\u001B[0m losses \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     35\u001B[0m mask_nums \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, (\n\u001B[1;32m     37\u001B[0m         transformer_feats, difficulty_feats, topic_feats,\n\u001B[1;32m     38\u001B[0m         eye_feats,\n\u001B[1;32m     39\u001B[0m         word_normal_labels, sent_normal_labels,\n\u001B[1;32m     40\u001B[0m         word_multilabel_labels, sent_multilabel_labels,\n\u001B[1;32m     41\u001B[0m         sent_mapping,\n\u001B[1;32m     42\u001B[0m         \u001B[38;5;66;03m# _,\u001B[39;00m\n\u001B[1;32m     43\u001B[0m         word_watching_situations, sent_watching_situations,\n\u001B[1;32m     44\u001B[0m ) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_dataloader):\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;66;03m# print(sent_mapping)\u001B[39;00m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;66;03m# raise Exception\u001B[39;00m\n\u001B[1;32m     47\u001B[0m     word_normal_cls, sent_normal_cls, _, sent_multilabel_cls \u001B[38;5;241m=\u001B[39m model(transformer_feats\u001B[38;5;241m.\u001B[39mcuda(), difficulty_feats\u001B[38;5;241m.\u001B[39mcuda(), topic_feats\u001B[38;5;241m.\u001B[39mcuda(), eye_feats\u001B[38;5;241m.\u001B[39mcuda(), sent_mapping[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m     48\u001B[0m     word_normal_weight \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[[\u001B[38;5;241m0.01\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m l \u001B[38;5;28;01melse\u001B[39;00m [\u001B[38;5;241m1.\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m word_normal_labels[\u001B[38;5;241m0\u001B[39m]]])\u001B[38;5;241m.\u001B[39mcuda()\n",
      "File \u001B[0;32m~/miniconda3/envs/memx4edu/lib/python3.9/site-packages/torch/utils/data/dataloader.py:681\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    680\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 681\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    684\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    685\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/memx4edu/lib/python3.9/site-packages/torch/utils/data/dataloader.py:721\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    719\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    720\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 721\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    722\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    723\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/miniconda3/envs/memx4edu/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/memx4edu/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:175\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    172\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [default_collate(samples) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/memx4edu/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:175\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    172\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    174\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 175\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mdefault_collate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    177\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/memx4edu/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:141\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    139\u001B[0m         storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mstorage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    140\u001B[0m         out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[0;32m--> 141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m elem_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__module__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m elem_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstr_\u001B[39m\u001B[38;5;124m'\u001B[39m \\\n\u001B[1;32m    143\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m elem_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstring_\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mndarray\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m elem_type\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmemmap\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    145\u001B[0m         \u001B[38;5;66;03m# array of string classes and object\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter('/home/wtpan/memx4edu-code/training_summary')\n",
    "\n",
    "# valid_accuracy = MultilabelAccuracy(num_labels=3, average=None)\n",
    "# valid_precision = MultilabelPrecision(num_labels=3, average=None)\n",
    "# valid_recall = MultilabelRecall(num_labels=3, average=None)\n",
    "# valid_f1_score = MultilabelF1Score(num_labels=3, average=None)\n",
    "# valid_hamming_distance = MultilabelHammingDistance(num_labels=3, average=None)\n",
    "validation_metrics = {\n",
    "    'word_normal': {\n",
    "        'accuracy': Accuracy(),\n",
    "        'precision': Precision(),\n",
    "        'recall': Recall(),\n",
    "        'f1_score': F1Score(),\n",
    "    },\n",
    "    'sent_normal': {\n",
    "        'accuracy': Accuracy(),\n",
    "        'precision': Precision(),\n",
    "        'recall': Recall(),\n",
    "        'f1_score': F1Score(),\n",
    "    },\n",
    "}\n",
    "\n",
    "# model = torch.load('/home/wtpan/memx4dog-code/cvr/saved_model/new_complete_model_0415_100000_0.652.pkl')\n",
    "model = ClassificationModel().cuda()\n",
    "\n",
    "print('Start training...')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "train_len = len(train_dataset)\n",
    "ALPHA, BETA = 1., 1.\n",
    "WORD_WINDOW_SIZE = 5\n",
    "SENT_WINDOW_SIZE = 1\n",
    "for epoch in range(50000):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    mask_nums = []\n",
    "    for step, (\n",
    "            transformer_feats, difficulty_feats, topic_feats,\n",
    "            eye_feats,\n",
    "            word_normal_labels, sent_normal_labels,\n",
    "            word_multilabel_labels, sent_multilabel_labels,\n",
    "            sent_mapping,\n",
    "            word_watching_situations, sent_watching_situations,\n",
    "    ) in enumerate(train_dataloader):\n",
    "        word_normal_cls, sent_normal_cls, _, sent_multilabel_cls = model(transformer_feats.cuda(), difficulty_feats.cuda(), topic_feats.cuda(), eye_feats.cuda(), sent_mapping[0])\n",
    "\n",
    "        word_normal_weight = torch.tensor([[[0.01] if l else [1.] for l in word_normal_labels[0]]]).cuda()\n",
    "        sent_normal_weight = torch.tensor([[[0.01] if l else [1.] for l in sent_normal_labels[0]]]).cuda()\n",
    "        # word_multilabel_weight = torch.tensor([[0.] if l else [1.] for l in word_normal_labels[0]]).cuda()\n",
    "        sent_multilabel_weight = torch.tensor([[[0.01, 0.01] if l else [1., 1.] for l in sent_normal_labels[0]]]).cuda()\n",
    "        word_normal_position_weight = torch.tensor([[[1.] if word_watching_situation else [0.] for word_watching_situation in word_watching_situations[0]]]).cuda()\n",
    "        sent_normal_position_weight = torch.tensor([[[1.] if sent_watching_situation else [0.] for sent_watching_situation in sent_watching_situations[0]]]).cuda()\n",
    "        # word_multilabel_position_weight = torch.tensor([[1. if word_watching_situation else 0. for word_watching_situation in word_watching_situations[0]]]).cuda()\n",
    "        sent_multilabel_position_weight = torch.tensor([[[1., 1.] if sent_watching_situation else [0., 0.] for sent_watching_situation in sent_watching_situations[0]]]).cuda()\n",
    "\n",
    "        word_normal_loss = nn.BCELoss(weight=word_normal_weight * word_normal_position_weight)(word_normal_cls, word_normal_labels.cuda())\n",
    "        sent_normal_loss = nn.BCELoss(weight=sent_normal_weight * sent_normal_position_weight)(sent_normal_cls, sent_normal_labels.cuda())\n",
    "        # word_multilabel_loss = nn.BCELoss()(word_multilabel_cls.squeeze(), word_multilabel_labels.squeeze().cuda())\n",
    "        sent_multilabel_loss = nn.BCELoss(weight=sent_multilabel_weight * sent_multilabel_position_weight)(sent_multilabel_cls, sent_multilabel_labels.cuda())\n",
    "\n",
    "        loss = word_normal_loss + ALPHA * sent_normal_loss + BETA * sent_multilabel_loss\n",
    "\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    loss_num = np.sum(losses) / train_len\n",
    "    writer.add_scalar('loss', loss_num, epoch)\n",
    "    print(epoch, loss_num)\n",
    "\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        model.eval()\n",
    "        pred_list = []\n",
    "        gt_list = []\n",
    "        for (\n",
    "                transformer_feats, difficulty_feats, topic_feats,\n",
    "                eye_feats,\n",
    "                word_normal_labels, sent_normal_labels,\n",
    "                word_multilabel_labels, sent_multilabel_labels,\n",
    "                sent_mapping,\n",
    "                word_watching_situations, sent_watching_situations,\n",
    "            ) in val_dataloader:\n",
    "            word_normal_cls, sent_normal_cls, _, sent_multilabel_cls = model(transformer_feats.cuda(), difficulty_feats.cuda(), topic_feats.cuda(), eye_feats.cuda(), sent_mapping[0])\n",
    "\n",
    "            current_position_predictions = {\n",
    "                'word_normal': word_normal_cls[ : , torch.nonzero(word_watching_situations[0]).squeeze(), : ].detach().cpu(),\n",
    "                'sent_normal': sent_normal_cls[ : , torch.nonzero(sent_watching_situations[0]).squeeze(), : ].detach().cpu(),\n",
    "            }\n",
    "            current_position_labels = {\n",
    "                'word_normal': word_normal_labels[ : , torch.nonzero(word_watching_situations[0]).squeeze(), : ].int(),\n",
    "                'sent_normal': sent_normal_labels[ : , torch.nonzero(sent_watching_situations[0]).squeeze(), : ].int(),\n",
    "            }\n",
    "\n",
    "            for x in validation_metrics:\n",
    "                for y in validation_metrics[x]:\n",
    "                    validation_metrics[x][y](current_position_predictions[x], current_position_labels[x])\n",
    "\n",
    "            # pred_list.append(cur_pred[0].numpy())\n",
    "            # gt_list.append(cur_label[0].numpy())\n",
    "\n",
    "        validation_metrics_value = {'word_normal': {}, 'sent_normal': {}}\n",
    "        for x in validation_metrics:\n",
    "            for y in validation_metrics[x]:\n",
    "                validation_metrics_value[x][y] = validation_metrics[x][y].compute().item()\n",
    "\n",
    "        writer.add_scalars('word_normal', validation_metrics_value['word_normal'], epoch)\n",
    "        writer.add_scalars('sent_normal', validation_metrics_value['sent_normal'], epoch)\n",
    "\n",
    "        torch.save(model, '/home/wtpan/memx4edu-code/saved_model/model_1018_%06d.pkl' % epoch)\n",
    "\n",
    "        for x in validation_metrics:\n",
    "            for y in validation_metrics[x]:\n",
    "                validation_metrics[x][y].reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [172], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m a \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m]])\n\u001B[1;32m      2\u001B[0m b \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mnonzero(a)\n\u001B[0;32m----> 3\u001B[0m \u001B[43ma\u001B[49m\u001B[43m[\u001B[49m\u001B[43mb\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[0;31mIndexError\u001B[0m: index 2 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 0, 1, 0]])\n",
    "b = torch.nonzero(a)\n",
    "a[b]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1., 1.])"
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([0.3,0.501,0.7])\n",
    "np.around(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "477"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.experiments[3].id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.5000)"
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import MultilabelPrecision\n",
    "target = torch.tensor([[0, 1, 0], [1, 0, 1]])\n",
    "preds = torch.tensor([[0, 0, 1], [1, 0, 1]])\n",
    "metric = MultilabelPrecision(num_labels=3, average='macro')\n",
    "metric(preds, target)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 512])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "src = torch.rand(1000, 512)\n",
    "out = encoder_layer(src)\n",
    "out.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
